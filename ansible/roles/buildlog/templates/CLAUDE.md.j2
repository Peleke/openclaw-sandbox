# OpenClaw Sandbox - Claude Instructions

This is a sandboxed VM environment for running AI agents with security isolation.

## buildlog (ALWAYS ON - USE AGGRESSIVELY)

buildlog is your **ambient data capture layer**. It captures structured trajectories from every session, extracts decision patterns, and uses statistical methods to improve over time.

**This is integral to the OpenClaw sandbox setup. USE IT FOR EVERYTHING.**

### MANDATORY: Core Loop After Every Significant Change

After EVERY commit, refactor, or significant code change, run this loop:

```
1. buildlog_overview()           — check project state
2. buildlog_commit(message="...") — git commit with auto-logging
3. buildlog_gauntlet_rules()     — load reviewer personas
4. Review your work against the rules
5. buildlog_gauntlet_issues([...]) — log any findings
6. buildlog_log_reward(outcome="accepted"|"rejected") — close the feedback loop
```

### Available MCP Tools (29 total)

**Session Management:**
| Tool | When to Use |
|------|-------------|
| `buildlog_overview()` | START OF EVERY SESSION - check project state |
| `buildlog_entry_new(slug)` | Start a new journal entry for a feature/task |
| `buildlog_entry_list()` | List existing entries |
| `buildlog_commit(message)` | ALWAYS use instead of raw git commit |

**Learning & Extraction:**
| Tool | When to Use |
|------|-------------|
| `buildlog_skills()` | Extract patterns, render to agent files |
| `buildlog_status()` | See extracted skills and their confidence |
| `buildlog_promote(skill_ids)` | Surface high-confidence skills to rules |
| `buildlog_distill()` | Distill learnings from recent work |

**Review Gauntlet:**
| Tool | When to Use |
|------|-------------|
| `buildlog_gauntlet_rules()` | Load reviewer personas before review |
| `buildlog_gauntlet_issues(issues)` | Log findings from review |
| `buildlog_gauntlet_prompt()` | Get the gauntlet prompt |
| `buildlog_gauntlet_loop()` | Run full gauntlet review cycle |
| `buildlog_gauntlet_accept_risk(issue_ids)` | Accept known risks |

**Experiments & Metrics:**
| Tool | When to Use |
|------|-------------|
| `buildlog_experiment_start()` | Begin an experiment |
| `buildlog_experiment_end()` | End current experiment |
| `buildlog_experiment_metrics()` | Get experiment metrics |
| `buildlog_experiment_report()` | Generate experiment report |

**Feedback Loop:**
| Tool | When to Use |
|------|-------------|
| `buildlog_log_reward(outcome)` | AFTER EVERY SIGNIFICANT ACTION |
| `buildlog_rewards()` | View reward history |
| `buildlog_log_mistake(description)` | Log mistakes for learning |
| `buildlog_learn_from_review()` | Extract learnings from reviews |

**Bandit & Diff:**
| Tool | When to Use |
|------|-------------|
| `buildlog_bandit_status()` | Check Thompson Sampling state |
| `buildlog_diff()` | View staged/unstaged changes |
| `buildlog_stats()` | Project statistics |
| `buildlog_init()` | Initialize buildlog in a new project |

### WHEN TO USE (Be Aggressive)

**ALWAYS use buildlog when:**
- Starting any coding session → `buildlog_overview()`
- Making ANY git commit → `buildlog_commit()` (NOT raw `git commit`)
- Finishing a feature/fix → `buildlog_gauntlet_loop()`
- Something works well → `buildlog_log_reward(outcome="accepted")`
- Something fails/breaks → `buildlog_log_reward(outcome="rejected")` + `buildlog_log_mistake()`
- Unsure about a pattern → Check `buildlog_skills()` for prior learnings
- Starting new work → `buildlog_entry_new(slug)`

**The philosophy:** Every decision, every outcome, every correction should be captured. The system learns from this data. Without capture, there is no learning.

### Security Note

buildlog captures development trajectories. In this sandboxed environment, that's acceptable - the VM is isolated. The data stays within the sandbox and feeds the learning loop.

## Environment

- **VM**: Ubuntu 24.04 via Lima
- **Network**: UFW firewall with explicit allowlist
- **Secrets**: `/etc/openclaw/secrets.env` (0600, never in logs)
- **OpenClaw**: `/mnt/openclaw`
- **Vault**: `/mnt/obsidian` (if mounted)
